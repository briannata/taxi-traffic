{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please run in google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the text file\n",
    "with open('drive/My Drive/December2019.txt', 'r') as f: #change the file name and path\n",
    "    stuff = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the dictionaries from the text file\n",
    "import ast\n",
    "a = stuff.index(\"=\")\n",
    "b = stuff.index(\"=\", a+1)\n",
    "taxi_string = stuff[a+2:b-17].strip()\n",
    "taxi_count = ast.literal_eval(taxi_string)\n",
    "mean_string = stuff[b+2:].strip()\n",
    "clusters_to_mean = ast.literal_eval(mean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array(sorted(list(taxi_count.keys())))\n",
    "num_of_areas = 50\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "#defining functions for nonlinear regression\n",
    "\n",
    "def fun(x, t, y):\n",
    "    return x[0] * np.exp(-x[1] * t) * np.sin(x[2] * t) - y\n",
    "\n",
    "def generate_data(t, A, sigma, omega, noise=0, n_outliers=0, random_state=0):\n",
    "    y = A * np.exp(-sigma * t) * np.sin(omega * t)\n",
    "    rnd = np.random.RandomState(random_state)\n",
    "    error = noise * rnd.randn(t.size)\n",
    "    outliers = rnd.randint(0, t.size, n_outliers)\n",
    "    error[outliers] *= 35\n",
    "    return y + error\n",
    "\n",
    "x0 = np.ones(3)\n",
    "\n",
    "predict_taxi_counts = {}\n",
    "\n",
    "#doing the nonlinear regression on each cluster over the time intervals\n",
    "\n",
    "for x in range(num_of_areas):\n",
    "  y = []\n",
    "  for i in range(len(t)):\n",
    "    if x in taxi_count[t[i]].keys():\n",
    "      y.append(taxi_count[t[i]][x])\n",
    "    else:\n",
    "      y.append(0)\n",
    "  y = np.array(y)\n",
    "  res_robust = least_squares(fun, x0, loss='soft_l1', f_scale=0.1, args=(t, y))\n",
    "  y_robust = generate_data(t, *res_robust.x)\n",
    "  for i in range(len(y_robust)):\n",
    "    if y_robust[i] < 0.5: num = 0\n",
    "    else: num = int(y_robust)\n",
    "    if t[i] in predict_taxi_counts.keys():\n",
    "      temp = predict_taxi_counts[t[i]]\n",
    "      temp[x] = num\n",
    "      predict_taxi_counts[t[i]] = temp\n",
    "    else:\n",
    "      predict_taxi_counts[t[i]] = {x: num}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/December2020.txt', 'w') as writefile: #change file name and path\n",
    "    writefile.write(\"taxi_count = \")\n",
    "    writefile.write(str(predict_taxi_counts))\n",
    "    writefile.write(\"clusters_to_mean = \")\n",
    "    writefile.write(str(clusters_to_mean))"
   ]
  }
 ]
}